{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Computational Lexical Semantics</center></h1>\n",
    "<h5><center>LIN5580-SEM1-A-1718</center></h5>\n",
    "<h3><center>Jovana Urosevic and Angelo Basile</center></h3>\n",
    "<h5><center>January 31, 2018</center></h5>\n",
    "\n",
    "-----\n",
    "### Instruction on how to use this notebook to replicate the results:\n",
    "\n",
    "1. download and install python 2\n",
    "2. download and install [pipenv](https://docs.pipenv.org/)\n",
    "3. install cython separately: ```pipenv install cython```\n",
    "4. install the requirements from the Pipfile\n",
    "5. active the virtualenvironment: ```pipenv shell```\n",
    "6. ```cd dissect-master```\n",
    "7. install dissect: ```pipenv run python2 setup.py install```\n",
    "8. deactive the virtual environment:```exit```\n",
    "9. run the notebook: ```pipenv run jupyter notebook```\n",
    "----\n",
    "\n",
    "TODO put toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that dissect is installed correctly:\n",
    "# this import should give no errors\n",
    "from composes.semantic_space.space import Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Describe the Distributional Hypothesis and explain how it can be used to find semantically similar words in corpora.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Because DSMs generate ranked lists of semantically similar words, they can be seen as alternatives to manually built lexical resources such as WordNet. \n",
    "- Explain the main differences between the lexical semantic content of WordNet and the lexical output of DSMs.\n",
    "- Discuss advantages and drawbacks of manually built lexical resources such as Wordnet and automatically generated lexical resources such as lists of semantically similar words stemming from DSMs. \n",
    "- Can you think of an application that would fare better when using WordNet and another thatwould benefit more from the output of DSMs? (5 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this assignment, in order to gather semantically similar words, we will use the following:\n",
    "**1. Data:**\n",
    "- A monolingual corpus. (English)\n",
    "- Word-aligned parallel texts for a language pair English-Spanish\n",
    "\n",
    "**2. Tools:**\n",
    "- an extraction program (for the extraction from the parallel text): a program that gathers coocurrence counts for the target words\n",
    "- a DSM tool, a program that will compute the similarity between the coocurrence vectors for the head words we are interested in â€“ taking the coocurrence matrix as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a coocurrence matrix from a corpus:\n",
    "There are several ways to build a coocurrence matrix depending on the target words you are selecting (parameter 1) and the type of features, more in particular, the type of context you are selecting (parameter 2). Please refer back to the slides of the lecture on DSMs for a list of parameters and a description of the options.\n",
    "\n",
    "#### *TARGET WORDS*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Does the monolingual corpus you are using to extract the cooccurrence counts from provide lemmas? Discuss why using lemmas instead of words often leads to better performances in DSMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Extra points: The parallel text does not provide lemma information, nor PoS tags. Run a PoS tagger on (both sides of) the parallel text and use the information it gives you for the DSM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data provided with DISSECT already selected target words for you. For the parallel text, and in case you selected your own monolingual text, we take the 1550 most frequent content words (lemmas) in the corpus as target words. In order to determine the 1550 most frequent content words in either corpus, you will need to count all content words. (If you do not have access to PoS information, use a list of stopwords that you filter out.) You then need to rank these words according to their frequency and take the top 1550."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Explain why PoS information can be useful for distinguishing between ambiguous terms. Give some examples from the data you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FEATURES*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Please discuss in your report, the different types of features, more in particular, the types of context (parameter 2) that are employed for DSMs in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the aligned parallel text, we are going to select the words that are aligned to the target word as features. Please select only the 10000 most frequent content words as features. If you opted to include your own monolingual corpus, we are going to select a small window of the content word following and the content word preceding the target word, as features. Please select only the 10000 most frequent content words as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Discuss what influence the size of the window has on the nature of the semantic relations we find between target word and semantically similar words proposed by the system. What consequences do you think a larger window size would have on the semantically similar words proposed by the system?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) Discuss the differences in output of the DSM (in terms of the similar words it will produce) you expect between the two types of input you are using (the monolingual corpus and the aligned parallel files). Which type of data do you think will generate the highest percentage of synonyms amongst the nearest neighbours?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9) Write a python program that extracts coocurrence counts for all target words and features from the parallel aligned files (and the monolingual corpus, if you are using a different corpus than the one provided by DISSECT).  Include the extraction program you wrote in the submission, and paste 20 lines (for 20 target words) of the coocurrence counts you extracted in the report. The output of your program should be formatted according to the input format the DSM tool you are using requires. (36 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Feature weighting and similarity function:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10) Explain what function the feature weighting scheme has. What would be the drawback of doing without a weighting scheme and using raw frequencies instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11) List the weighting schemes the tool you are using includes and what similarity functions. Make your choice for the weighting scheme and similarity function you will use and motivate your choice in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
